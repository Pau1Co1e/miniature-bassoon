{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "# models and algorithms\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Load the Dataset\n",
    "train_df = pd.read_csv('data/train/train.csv')\n",
    "test_df = pd.read_csv('data/test/test.csv')\n",
    "combine_df = [train_df, test_df]\n",
    "\n",
    "# Step 2: Feature Engineering\n",
    "# Extract titles from names\n",
    "def extract_title(name):\n",
    "    return name.split(', ')[1].split('.')[0]\n",
    "\n",
    "for dataset in combine_df:\n",
    "    dataset['Title'] = dataset['Name'].apply(extract_title)\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "    dataset['IsAlone'] = 1  # Initialize to being alone\n",
    "    dataset.loc[dataset['FamilySize'] > 1, 'IsAlone'] = 0  # Fixing chained assignment warning\n",
    "    dataset['CabinKnown'] = dataset['Cabin'].apply(lambda x: 0 if pd.isna(x) else 1)\n",
    "\n",
    "# Fill missing Age values by grouping by Title\n",
    "age_fill_values = train_df.groupby('Title')['Age'].median()\n",
    "for dataset in combine_df:\n",
    "    dataset['Age'] = dataset.apply(lambda row: age_fill_values[row['Title']] if pd.isna(row['Age']) else row['Age'], axis=1)\n",
    "\n",
    "# Fill missing Embarked values with the most common port\n",
    "most_common_port = train_df['Embarked'].mode()[0]\n",
    "for dataset in combine_df:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna(most_common_port)\n",
    "\n",
    "# Fill missing Fare values with the median of Fare\n",
    "for dataset in combine_df:\n",
    "    dataset['Fare'] = dataset['Fare'].fillna(train_df['Fare'].median())\n",
    "\n",
    "# Step 3: Encoding categorical features\n",
    "encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "categorical_features = ['Sex', 'Embarked', 'Title']\n",
    "\n",
    "# Fit encoder on combined data to handle any category differences\n",
    "encoder.fit(pd.concat([train_df[categorical_features], test_df[categorical_features]], axis=0))\n",
    "\n",
    "encoded_train = pd.DataFrame(encoder.transform(train_df[categorical_features]),\n",
    "                             columns=encoder.get_feature_names_out(categorical_features))\n",
    "encoded_test = pd.DataFrame(encoder.transform(test_df[categorical_features]),\n",
    "                            columns=encoder.get_feature_names_out(categorical_features))\n",
    "\n",
    "# Drop unused features and concatenate encoded features\n",
    "drop_columns = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'Sex', 'Embarked', 'Title']\n",
    "train_df = train_df.drop(drop_columns, axis=1)\n",
    "test_df = test_df.drop(drop_columns, axis=1)\n",
    "\n",
    "train_df = pd.concat([train_df, encoded_train], axis=1)\n",
    "test_df = pd.concat([test_df, encoded_test], axis=1)\n",
    "\n",
    "# Step 4: Model Training and Hyperparameter Tuning\n",
    "# Define features and labels\n",
    "X_train = train_df.drop('Survived', axis=1)\n",
    "y_train = train_df['Survived']\n",
    "\n",
    "# Define the models\n",
    "logreg = LogisticRegression(max_iter=200)\n",
    "random_forest = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "xgb_clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "svc = SVC(probability=True)\n",
    "\n",
    "# Hyperparameter tuning for SVM\n",
    "param_grid = {'C': [0.1, 1, 10], 'kernel': ['rbf', 'poly', 'linear']}\n",
    "grid_search_svc = GridSearchCV(svc, param_grid, cv=5)\n",
    "grid_search_svc.fit(X_train, y_train)\n",
    "svc_best = grid_search_svc.best_estimator_\n",
    "\n",
    "# Ensemble Voting Classifier\n",
    "voting_clf = VotingClassifier(estimators=[('rf', random_forest), ('svc', svc_best), ('xgb', xgb_clf)], voting='soft')\n",
    "\n",
    "# Cross-validation\n",
    "kfold = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n",
    "scores = cross_val_score(voting_clf, X_train, y_train, cv=kfold)\n",
    "print(f'Cross-Validation Accuracy: {scores.mean():.4f} (+/- {scores.std():.4f})')\n",
    "\n",
    "# Train the voting classifier\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Predictions\n",
    "X_test = test_df\n",
    "predictions = voting_clf.predict(X_test)\n",
    "\n",
    "# Save predictions to submission file\n",
    "submission = pd.DataFrame({'PassengerId': test_df.index + 892, 'Survived': predictions})\n",
    "submission.to_csv('/mnt/data/submission.csv', index=False)\n",
    "\n",
    "print(\"Model training and predictions complete. Submission file created.\")\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
