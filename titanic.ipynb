{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Exploratory Data Analysis",
   "id": "f5fb4cb5b8cc9146"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Data Dictionary\n",
    "\n",
    "| Variable   | Definition                            | Key                            |\n",
    "|------------|---------------------------------------|--------------------------------|\n",
    "| survival   | Survival                              | 0 = No, 1 = Yes                |\n",
    "| pclass     | Ticket class                          | 1 = 1st, 2 = 2nd, 3 = 3rd      |\n",
    "| sex        | Sex                                   |                                |\n",
    "| Age        | Age in years                          |                                |\n",
    "| sibsp      | # of siblings/spouses aboard Titanic  |                                |\n",
    "| parch      | # of parents/children aboard Titanic  |                                |\n",
    "| ticket     | Ticket number                         |                                |\n",
    "| fare       | Passenger fare                        |                                |\n",
    "| cabin      | Cabin number                          |                                |\n",
    "| embarked   | Port of Embarkation                   | C = Cherbourg, Q = Queenstown, S = Southampton |\n"
   ],
   "id": "5fba70c6e9d60c37"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1. Problem Definition",
   "id": "717b5f7f4ddb6f7c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\n",
    "### Specific Task: find patterns in train.csv that help predict whether the passengers in test.csv survived."
   ],
   "id": "cd026546f7fc5e55"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2. Data Collection and Exploration",
   "id": "59a87a27c71224ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Step 1: Load the Dataset\n",
    "train_df = pd.read_csv('data/train/train.csv')\n",
    "test_df = pd.read_csv('data/test/test.csv')\n",
    "combine_df = [train_df, test_df]\n"
   ],
   "id": "ce7ac343ede7d944"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Features\n",
    "print(f\"Features:\\n{train_df.columns.values}\")\n",
    "print()\n",
    "\n",
    "# Display first few rows of train and test data\n",
    "train_df.head()\n",
    "test_df.head()\n",
    "\n",
    "# Summary statistics\n",
    "print(train_df.describe())\n",
    "print(test_df.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(train_df.isnull().sum())\n",
    "print(test_df.isnull().sum())\n"
   ],
   "id": "525103d9e82b74",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Visualize Survival Rates by Gender",
   "id": "a5b7e76d9530df1f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Plot survival rates by gender\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='Sex', hue='Survived', data=train_df, palette='Set1')\n",
    "plt.title(\"Survival Rates by Gender\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ],
   "id": "9d8ef892f9367c10",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Visualize Survival Rates by Passenger Class",
   "id": "4e1655e71bf1b2e6"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Plot survival rates by passenger class\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='Pclass', hue='Survived', data=train_df, palette='Set1', legend=True)\n",
    "plt.title(\"Survival Rates by Passenger Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Visualize Survival Rates by Age",
   "id": "77d192c1bf06ca3a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create a plot that shows survival based on age\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(data=train_df, x='Age', hue='Survived', multiple='stack', bins=30, palette='Set1')\n",
    "plt.title(\"Survival Rates by Age\")\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ],
   "id": "3578bf15227fa3de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Visualize Age Distribution of Passengers",
   "id": "f10b4dfbe29eead1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot the distribution of age\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(train_df['Age'].dropna(), bins=30, kde=True, color='red')\n",
    "plt.title(\"Age Distribution of Passengers\")\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ],
   "id": "144c0d751043a7c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3. Feature Engineering",
   "id": "13cb539bf2aec732"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Preprocessing function to handle missing values, encoding, and scaling\n",
    "def preprocess_data(df):\n",
    "    # Fill missing age values with the median\n",
    "    df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "\n",
    "    # Fill missing embarked values with the most common value\n",
    "    df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])\n",
    "\n",
    "    # Fill missing fare values with the median (important for test data)\n",
    "    df['Fare'] = df['Fare'].fillna(df['Fare'].median())\n",
    "\n",
    "    # Create a new feature 'CabinAvailable' to indicate whether cabin info is available\n",
    "    df['CabinAvailable'] = df['Cabin'].apply(lambda x: 0 if pd.isna(x) else 1)\n",
    "\n",
    "    # Family Size: Combine SibSp and Parch into a single feature, FamilySize\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "\n",
    "    # Extract title from the Name column (e.g., Mr., Mrs., Miss)\n",
    "    df['Title'] = df['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())\n",
    "\n",
    "    # Drop unnecessary columns ('Name', 'Ticket', 'Cabin', 'PassengerId')\n",
    "    columns_to_drop = ['Name', 'Ticket', 'Cabin', 'PassengerId']\n",
    "    df = df.drop(columns_to_drop, axis=1, errors='ignore')\n",
    "\n",
    "    # Encode categorical variables (Sex, Embarked, Title)\n",
    "    df = pd.get_dummies(df, columns=['Sex', 'Embarked', 'Title'], drop_first=True)\n",
    "\n",
    "    # Scale continuous variables (Fare and Age)\n",
    "    scaler = StandardScaler()\n",
    "    df[['Fare', 'Age']] = scaler.fit_transform(df[['Fare', 'Age']])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Load the train and test datasets\n",
    "train_df = pd.read_csv('data/train/train.csv')\n",
    "test_df = pd.read_csv('data/test/test.csv')\n",
    "\n",
    "# Step 2: Store PassengerId from test_df before preprocessing\n",
    "passenger_id_test = test_df['PassengerId'].copy()\n",
    "\n",
    "# Apply preprocessing to both train and test datasets\n",
    "train_df = preprocess_data(train_df)\n",
    "test_df = preprocess_data(test_df)\n",
    "\n",
    "# Step 3: Define features and target variable for training\n",
    "X_train = train_df.drop('Survived', axis=1)\n",
    "y_train = train_df['Survived']\n",
    "\n",
    "# Align test set with the training set columns\n",
    "train_columns = X_train.columns\n",
    "X_test = test_df.copy()\n",
    "\n",
    "# Add missing columns in the test set\n",
    "for col in train_columns:\n",
    "    if col not in X_test.columns:\n",
    "        X_test[col] = 0\n",
    "\n",
    "# Ensure test set has the same columns as the train set\n",
    "X_test = X_test[train_columns]\n"
   ],
   "id": "5e3cd2c7e1d0789",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Step 4: Model Building",
   "id": "89e8009ef42595ba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Select and Initialize models\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "svm_model = SVC()\n",
    "\n",
    "# Step 4: Cross-validate Logistic Regression\n",
    "cv_scores_logreg = cross_val_score(logreg, X_train, y_train, cv=5, scoring='accuracy')\n",
    "logreg_accuracy = cv_scores_logreg.mean()\n",
    "\n",
    "# Step 5: Cross-validate Random Forest\n",
    "cv_scores_rf = cross_val_score(rf, X_train, y_train, cv=5, scoring='accuracy')\n",
    "rf_accuracy = cv_scores_rf.mean()\n",
    "\n",
    "# Step 6: Cross-validate SVM\n",
    "cv_scores_svm = cross_val_score(svm_model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "svm_accuracy = cv_scores_svm.mean()\n",
    "\n",
    "# Output cross-validation accuracies\n",
    "print(f\"Logistic Regression Cross-Validation Accuracy: {logreg_accuracy:.4f}\")\n",
    "print(f\"Random Forest Cross-Validation Accuracy: {rf_accuracy:.4f}\")\n",
    "print(f\"SVM Cross-Validation Accuracy: {svm_accuracy:.4f}\")\n"
   ],
   "id": "e2e54660b56edbfb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Hyperparameter Tuning",
   "id": "1e0f94c424840c02"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Step 1: Define parameter grids for each model\n",
    "\n",
    "# Logistic Regression parameters\n",
    "param_grid_logreg = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'lbfgs']\n",
    "}\n",
    "\n",
    "# Random Forest parameters\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# SVM parameters\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Step 2: Hyperparameter tuning with GridSearchCV\n",
    "\n",
    "# Logistic Regression tuning\n",
    "grid_search_logreg = GridSearchCV(LogisticRegression(max_iter=1000), param_grid_logreg, cv=5, scoring='accuracy')\n",
    "grid_search_logreg.fit(X_train, y_train)\n",
    "\n",
    "# Random Forest tuning\n",
    "grid_search_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf, cv=5, scoring='accuracy')\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# SVM tuning\n",
    "grid_search_svm = GridSearchCV(SVC(), param_grid_svm, cv=5, scoring='accuracy')\n",
    "grid_search_svm.fit(X_train, y_train)\n"
   ],
   "id": "db6969de7e44b3e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 5. Model Evaluation - Precision, Cross Validation",
   "id": "98c52654b2e00ed5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 3: Display the best parameters and cross-validation score for each model\n",
    "print(\"Best parameters for Logistic Regression:\", grid_search_logreg.best_params_)\n",
    "print(f\"Best cross-validation accuracy for Logistic Regression: {grid_search_logreg.best_score_:.4f}\")\n",
    "\n",
    "print(\"Best parameters for Random Forest:\", grid_search_rf.best_params_)\n",
    "print(f\"Best cross-validation accuracy for Random Forest: {grid_search_rf.best_score_:.4f}\")\n",
    "\n",
    "print(\"Best parameters for SVM:\", grid_search_svm.best_params_)\n",
    "print(f\"Best cross-validation accuracy for SVM: {grid_search_svm.best_score_:.4f}\")"
   ],
   "id": "82f07bb28a040e61",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 6. Generate Predictions Using the Best SVM Model",
   "id": "b742588866a0dcbe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Select best model\n",
    "best_model = grid_search_svm.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred_final = best_model.predict(X_test)"
   ],
   "id": "b6abacdd983590c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 7. Prepare Submission Dataframe",
   "id": "a8db0623dd3fc3d7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Prepare the submission dataframe\n",
    "submission = pd.DataFrame({\n",
    "    \"PassengerId\": passenger_id_test,  # Use the PassengerId saved earlier\n",
    "    \"Survived\": y_pred_final           # Predictions from the best model\n",
    "})\n",
    "\n",
    "# Save the submission to a CSV file\n",
    "submission.to_csv('titanic_submission.csv', index=False)\n",
    "\n",
    "print(\"Submission file 'titanic_submission.csv' generated successfully.\")"
   ],
   "id": "5e217563719e8087",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
